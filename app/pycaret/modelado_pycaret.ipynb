{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f072835",
   "metadata": {},
   "source": [
    "1. Instalación y Configuración Inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c64e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos PyCaret y otras bibliotecas necesarias\n",
    "#!pip install pycaret matplotlib seaborn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f85a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pycaret.classification import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración para visualizaciones\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efb938",
   "metadata": {},
   "source": [
    "2. Carga y Exploración de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ddccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "df = pd.read_csv('data_set_integrado_modelo_final.csv')\n",
    "\n",
    "# Verificamos las dimensiones del dataset\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"Número de filas: {df.shape[0]}\")\n",
    "print(f\"Número de columnas: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee79a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploramos las primeras filas del dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6170a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos los tipos de datos\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la distribución de las clases objetivo\n",
    "print(\"Distribución de la variable 'label':\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Visualizamos la distribución\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title('Distribución de Clases en el Dataset Completo')\n",
    "plt.ylabel('Conteo')\n",
    "plt.xlabel('Clase')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e6bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos las empresas únicas en el dataset\n",
    "empresas = df['id_empresa'].unique()\n",
    "print(f\"Número de empresas distintas: {len(empresas)}\")\n",
    "print(\"IDs de empresas:\", empresas)\n",
    "\n",
    "# Visualizamos la distribución de registros por empresa\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(x='id_empresa', data=df)\n",
    "plt.title('Cantidad de Registros por Empresa')\n",
    "plt.ylabel('Conteo')\n",
    "plt.xlabel('ID de Empresa')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinamos la distribución de clases por empresa\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, emp in enumerate(empresas, 1):\n",
    "    plt.subplot(2, (len(empresas)+1)//2, i)\n",
    "    emp_df = df[df['id_empresa'] == emp]\n",
    "    sns.countplot(x='label', data=emp_df)\n",
    "    plt.title(f'Empresa {emp}')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238ce319",
   "metadata": {},
   "source": [
    "3. Preparación de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza básica del dataset\n",
    "def preparar_datos(dataframe):\n",
    "    # Hacemos una copia para no modificar el original\n",
    "    df_clean = dataframe.copy()\n",
    "    \n",
    "    # 1. Eliminar filas sin etiqueta\n",
    "    df_clean = df_clean.dropna(subset=['label'])\n",
    "    \n",
    "    # 2. Verificar valores nulos\n",
    "    print(\"Valores nulos por columna:\")\n",
    "    print(df_clean.isnull().sum())\n",
    "    \n",
    "    # 3. Eliminar columnas con más del 50% de valores faltantes\n",
    "    threshold = 0.5\n",
    "    missing_ratio = df_clean.isnull().mean()\n",
    "    cols_to_drop = missing_ratio[missing_ratio > threshold].index.tolist()\n",
    "    if cols_to_drop:\n",
    "        print(f\"Columnas eliminadas por tener más del 50% de valores nulos: {cols_to_drop}\")\n",
    "        df_clean = df_clean.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # 4. Eliminar cualquier fila restante con valores faltantes\n",
    "    rows_before = df_clean.shape[0]\n",
    "    df_clean = df_clean.dropna()\n",
    "    rows_after = df_clean.shape[0]\n",
    "    print(f\"Se eliminaron {rows_before - rows_after} filas con valores nulos.\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicamos la limpieza\n",
    "df_clean = preparar_datos(df)\n",
    "\n",
    "# Verificamos la forma del dataset después de la limpieza\n",
    "print(f\"Dimensiones después de la limpieza: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde08b89",
   "metadata": {},
   "source": [
    "4. Análisis Exploratorio de Características\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ab290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos las correlaciones entre variables numéricas\n",
    "# Seleccionamos solo columnas numéricas\n",
    "numeric_cols = df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_cols = [col for col in numeric_cols if col != 'id_empresa' and col != 'id_cotizacion']\n",
    "\n",
    "# Calculamos la matriz de correlación\n",
    "corr_matrix = df_clean[numeric_cols].corr()\n",
    "\n",
    "# Visualizamos el mapa de calor de correlaciones\n",
    "plt.figure(figsize=(16, 14))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title('Matriz de Correlación de Variables Numéricas')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos variables altamente correlacionadas para posible eliminación\n",
    "high_corr_threshold = 0.9\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(numeric_cols)):\n",
    "    for j in range(i+1, len(numeric_cols)):\n",
    "        corr = abs(corr_matrix.iloc[i, j])\n",
    "        if corr > high_corr_threshold:\n",
    "            high_corr_pairs.append((numeric_cols[i], numeric_cols[j], corr))\n",
    "\n",
    "# Mostramos las variables altamente correlacionadas\n",
    "if high_corr_pairs:\n",
    "    print(\"Variables altamente correlacionadas (|r| > 0.9):\")\n",
    "    for var1, var2, corr in high_corr_pairs:\n",
    "        print(f\"{var1} - {var2}: {corr:.4f}\")\n",
    "else:\n",
    "    print(\"No se encontraron pares de variables con correlación mayor a 0.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e3ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir y evaluar modelos para una empresa específica\n",
    "def modelar_empresa(df, empresa_id):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Modelado para la empresa {empresa_id}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Filtramos solo los datos de esta empresa\n",
    "    empresa_df = df[df['id_empresa'] == empresa_id].copy()\n",
    "    print(f\"Número de registros para la empresa {empresa_id}: {empresa_df.shape[0]}\")\n",
    "    \n",
    "    # Verificamos la distribución de clases\n",
    "    print(\"\\nDistribución de clases:\")\n",
    "    print(empresa_df['label'].value_counts())\n",
    "    \n",
    "    # Verificamos si hay suficientes datos\n",
    "    if empresa_df.shape[0] < 30:\n",
    "        print(f\"ADVERTENCIA: La empresa {empresa_id} tiene muy pocos registros para modelar adecuadamente.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Eliminamos columnas no necesarias para el modelado\n",
    "    cols_to_drop = ['id_cotizacion', 'id_empresa']\n",
    "    modelo_df = empresa_df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Inicializamos PyCaret\n",
    "    exp_name = f\"Empresa_{empresa_id}\"\n",
    "    print(\"\\nConfigurando ambiente PyCaret...\")\n",
    "    \n",
    "    clf = setup(\n",
    "        data=modelo_df,\n",
    "        target='label',\n",
    "        session_id=42,\n",
    "        experiment_name=exp_name,\n",
    "        normalize=True,\n",
    "        transformation=True,\n",
    "        ignore_features=['fecha', 'nombre'],\n",
    "        html=False,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Comparamos modelos\n",
    "    print(\"\\nComparando modelos...\")\n",
    "    top_models = compare_models(n_select=3)\n",
    "    \n",
    "    # Si top_models es un solo modelo y no una lista, lo convertimos a lista\n",
    "    if not isinstance(top_models, list):\n",
    "        top_models = [top_models]\n",
    "    \n",
    "    # Creamos un diccionario para almacenar los resultados\n",
    "    resultados = {}\n",
    "    \n",
    "    # Evaluamos cada uno de los modelos top\n",
    "    print(\"\\nEvaluando modelos seleccionados...\")\n",
    "    for i, model in enumerate(top_models):\n",
    "        model_name = str(type(model).__name__)\n",
    "        print(f\"\\nEvaluando {model_name}...\")\n",
    "        \n",
    "        # Evaluamos el modelo\n",
    "        evaluation = evaluate_model(model)\n",
    "        \n",
    "        # Creamos un modelo ajustado (tuneado)\n",
    "        print(f\"Tuneando {model_name}...\")\n",
    "        tuned_model = tune_model(model)\n",
    "        \n",
    "        # Visualizamos la matriz de confusión del modelo ajustado\n",
    "        plot_model(tuned_model, plot='confusion_matrix', save=True)\n",
    "        \n",
    "        # Visualizamos la curva AUC del modelo ajustado (para multiclase)\n",
    "        plot_model(tuned_model, plot='auc', save=True)\n",
    "        \n",
    "        # Visualizamos feature importance\n",
    "        if hasattr(tuned_model, 'feature_importances_') or hasattr(tuned_model, 'coef_'):\n",
    "            plot_model(tuned_model, plot='feature', save=True)\n",
    "        \n",
    "        # Guardamos el modelo\n",
    "        model_path = f\"modelo_{empresa_id}_{model_name}\"\n",
    "        print(f\"Guardando modelo en {model_path}...\")\n",
    "        save_model(tuned_model, model_path)\n",
    "        \n",
    "        resultados[model_name] = tuned_model\n",
    "    \n",
    "    # Finalizamos\n",
    "    print(f\"\\nModelado completo para la empresa {empresa_id}\")\n",
    "    \n",
    "    # Retornamos el DataFrame de la empresa, los modelos y los resultados\n",
    "    return empresa_df, top_models, resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc000f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos el modelado para cada empresa\n",
    "resultados_por_empresa = {}\n",
    "\n",
    "for empresa_id in empresas:\n",
    "    print(f\"\\nProcesando empresa {empresa_id}...\")\n",
    "    empresa_df, modelos, resultados = modelar_empresa(df_clean, empresa_id)\n",
    "    \n",
    "    if resultados:\n",
    "        resultados_por_empresa[empresa_id] = {\n",
    "            'dataframe': empresa_df,\n",
    "            'modelos': modelos,\n",
    "            'resultados': resultados\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3b028",
   "metadata": {},
   "source": [
    "6. Análisis Comparativo de Modelos entre Empresas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a87c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un DataFrame con los resultados comparativos\n",
    "resumen_empresas = pd.DataFrame(columns=['Empresa', 'Mejor_Modelo', 'Accuracy', 'Precision', 'Recall', 'F1', 'Num_Registros'])\n",
    "\n",
    "for empresa_id, datos in resultados_por_empresa.items():\n",
    "    if 'modelos' in datos and datos['modelos']:\n",
    "        # Obtenemos el mejor modelo (el primero de la lista)\n",
    "        mejor_modelo = datos['modelos'][0]\n",
    "        modelo_nombre = str(type(mejor_modelo).__name__)\n",
    "        \n",
    "        # Obtenemos métricas del pull_metrics \n",
    "        metricas = pull()\n",
    "        mejor_modelo_metricas = metricas[metricas['Model'] == modelo_nombre].iloc[0]\n",
    "        \n",
    "        # Añadimos al DataFrame\n",
    "        resumen_empresas = resumen_empresas.append({\n",
    "            'Empresa': empresa_id,\n",
    "            'Mejor_Modelo': modelo_nombre,\n",
    "            'Accuracy': mejor_modelo_metricas['Accuracy'],\n",
    "            'Precision': mejor_modelo_metricas['Prec. Macro'],\n",
    "            'Recall': mejor_modelo_metricas['Recall Macro'],\n",
    "            'F1': mejor_modelo_metricas['F1 Macro'],\n",
    "            'Num_Registros': datos['dataframe'].shape[0]\n",
    "        }, ignore_index=True)\n",
    "\n",
    "# Mostramos el resumen\n",
    "print(\"Resumen Comparativo de Modelos por Empresa:\")\n",
    "resumen_empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos las métricas por empresa\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.barplot(x='Empresa', y='Accuracy', data=resumen_empresas)\n",
    "plt.title('Accuracy por Empresa')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Precision\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.barplot(x='Empresa', y='Precision', data=resumen_empresas)\n",
    "plt.title('Precision por Empresa')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Recall\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(x='Empresa', y='Recall', data=resumen_empresas)\n",
    "plt.title('Recall por Empresa')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# F1\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(x='Empresa', y='F1', data=resumen_empresas)\n",
    "plt.title('F1-Score por Empresa')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación de modelos por empresa\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='Mejor_Modelo', data=resumen_empresas)\n",
    "plt.title('Distribución de Mejores Modelos por Empresa')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Conteo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6940310a",
   "metadata": {},
   "source": [
    "7. Análisis de Importancia de Características\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51522634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para analizar las características más importantes para cada empresa\n",
    "def analizar_features_importancia():\n",
    "    for empresa_id, datos in resultados_por_empresa.items():\n",
    "        if 'resultados' in datos and datos['resultados']:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Características importantes para la empresa {empresa_id}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Iteramos por los modelos disponibles\n",
    "            for modelo_nombre, modelo in datos['resultados'].items():\n",
    "                print(f\"\\nModelo: {modelo_nombre}\")\n",
    "                \n",
    "                # Intentamos obtener importancia de características si está disponible\n",
    "                try:\n",
    "                    # Para modelos basados en árboles\n",
    "                    if hasattr(modelo, 'feature_importances_'):\n",
    "                        # Obtenemos los nombres de las características del setup de PyCaret\n",
    "                        feature_names = get_config('X_train').columns.tolist()\n",
    "                        importances = modelo.feature_importances_\n",
    "                        \n",
    "                        # Crear DataFrame de importancias\n",
    "                        feature_importance = pd.DataFrame({\n",
    "                            'Feature': feature_names,\n",
    "                            'Importance': importances\n",
    "                        })\n",
    "                        \n",
    "                        # Ordenar por importancia\n",
    "                        feature_importance = feature_importance.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "                        \n",
    "                        # Mostrar las 10 características más importantes\n",
    "                        print(\"Top 10 características más importantes:\")\n",
    "                        print(feature_importance.head(10))\n",
    "                        \n",
    "                        # Visualizar\n",
    "                        plt.figure(figsize=(12, 8))\n",
    "                        sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "                        plt.title(f'Importancia de Características - Empresa {empresa_id} - {modelo_nombre}')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    \n",
    "                    # Para modelos lineales\n",
    "                    elif hasattr(modelo, 'coef_'):\n",
    "                        feature_names = get_config('X_train').columns.tolist()\n",
    "                        \n",
    "                        # Los coeficientes pueden tener diferentes formas según el modelo\n",
    "                        if len(modelo.coef_.shape) == 1:\n",
    "                            coefs = modelo.coef_\n",
    "                        else:\n",
    "                            # Promediamos coeficientes para todas las clases\n",
    "                            coefs = np.mean(np.abs(modelo.coef_), axis=0)\n",
    "                        \n",
    "                        # Crear DataFrame de coeficientes\n",
    "                        feature_importance = pd.DataFrame({\n",
    "                            'Feature': feature_names,\n",
    "                            'Coefficient': coefs\n",
    "                        })\n",
    "                        \n",
    "                        # Ordenar por valor absoluto de coeficientes\n",
    "                        feature_importance['AbsCoef'] = np.abs(feature_importance['Coefficient'])\n",
    "                        feature_importance = feature_importance.sort_values('AbsCoef', ascending=False).reset_index(drop=True)\n",
    "                        \n",
    "                        # Mostrar las 10 características más importantes\n",
    "                        print(\"Top 10 características más importantes:\")\n",
    "                        print(feature_importance[['Feature', 'Coefficient']].head(10))\n",
    "                        \n",
    "                        # Visualizar\n",
    "                        plt.figure(figsize=(12, 8))\n",
    "                        sns.barplot(x='AbsCoef', y='Feature', data=feature_importance.head(15))\n",
    "                        plt.title(f'Importancia de Características - Empresa {empresa_id} - {modelo_nombre}')\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    \n",
    "                    else:\n",
    "                        print(\"Este modelo no proporciona medidas directas de importancia de características.\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error al analizar importancia de características: {str(e)}\")\n",
    "\n",
    "# Ejecutamos el análisis de características\n",
    "analizar_features_importancia()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d231e6",
   "metadata": {},
   "source": [
    "8. Prueba y Predicción con los Modelos Guardados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb17325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para cargar un modelo y hacer predicciones de ejemplo\n",
    "def probar_modelo(empresa_id, modelo_nombre):\n",
    "    try:\n",
    "        # Cargamos el modelo\n",
    "        model_path = f\"modelo_{empresa_id}_{modelo_nombre}\"\n",
    "        modelo_cargado = load_model(model_path)\n",
    "        \n",
    "        print(f\"Modelo cargado correctamente: {model_path}\")\n",
    "        \n",
    "        # Obtenemos algunos datos de ejemplo para esta empresa\n",
    "        empresa_df = resultados_por_empresa[empresa_id]['dataframe']\n",
    "        \n",
    "        # Tomamos las últimas 5 filas como ejemplo\n",
    "        datos_ejemplo = empresa_df.tail(5).drop(columns=['label'])\n",
    "        \n",
    "        # Hacemos predicciones\n",
    "        predicciones = predict_model(modelo_cargado, data=datos_ejemplo)\n",
    "        \n",
    "        print(\"\\nPredicciones de ejemplo:\")\n",
    "        print(predicciones[['fecha', 'prediction_label', 'prediction_score']])\n",
    "        \n",
    "        return predicciones\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar o usar el modelo: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Probamos con un ejemplo para la primera empresa y su mejor modelo\n",
    "if resultados_por_empresa:\n",
    "    primera_empresa = list(resultados_por_empresa.keys())[0]\n",
    "    mejor_modelo_nombre = str(type(resultados_por_empresa[primera_empresa]['modelos'][0]).__name__)\n",
    "    \n",
    "    print(f\"Probando predicciones para la empresa {primera_empresa} con el modelo {mejor_modelo_nombre}\")\n",
    "    predicciones_ejemplo = probar_modelo(primera_empresa, mejor_modelo_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3032b1",
   "metadata": {},
   "source": [
    "9. Conclusiones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af698bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen y conclusiones\n",
    "print(\"RESUMEN DEL ANÁLISIS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total de empresas analizadas: {len(resultados_por_empresa)}\")\n",
    "\n",
    "# Modelos más efectivos\n",
    "if not resumen_empresas.empty:\n",
    "    mejor_empresa = resumen_empresas.iloc[resumen_empresas['Accuracy'].idxmax()]\n",
    "    print(f\"\\nEmpresa con mejor rendimiento: {mejor_empresa['Empresa']}\")\n",
    "    print(f\"- Mejor modelo: {mejor_empresa['Mejor_Modelo']}\")\n",
    "    print(f\"- Accuracy: {mejor_empresa['Accuracy']:.4f}\")\n",
    "    print(f\"- F1-Score: {mejor_empresa['F1']:.4f}\")\n",
    "    \n",
    "    # Modelos más frecuentes\n",
    "    modelo_mas_comun = resumen_empresas['Mejor_Modelo'].mode()[0]\n",
    "    print(f\"\\nModelo más común entre todas las empresas: {modelo_mas_comun}\")\n",
    "    \n",
    "    # Promedio de métricas\n",
    "    print(\"\\nRendimiento promedio de los modelos:\")\n",
    "    print(f\"- Accuracy promedio: {resumen_empresas['Accuracy'].mean():.4f}\")\n",
    "    print(f\"- Precision promedio: {resumen_empresas['Precision'].mean():.4f}\")\n",
    "    print(f\"- Recall promedio: {resumen_empresas['Recall'].mean():.4f}\")\n",
    "    print(f\"- F1-Score promedio: {resumen_empresas['F1'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nCONCLUSIONES:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. Hemos construido modelos de clasificación multiclase para predecir los movimientos \n",
    "   del mercado (SUBE, BAJA, MANTIENE) para cada empresa en el dataset.\n",
    "\n",
    "2. Para cada empresa, hemos identificado las características más relevantes que \n",
    "   influyen en los movimientos de sus acciones.\n",
    "\n",
    "3. Se han guardado los modelos entrenados para cada empresa, que pueden ser utilizados \n",
    "   para hacer predicciones futuras sobre nuevos datos.\n",
    "\n",
    "4. Los resultados muestran diferentes niveles de predictibilidad entre las empresas, \n",
    "   lo que sugiere que algunos movimientos de mercado son más fáciles de predecir que otros.\n",
    "\n",
    "5. Recomendaciones para mejorar los modelos:\n",
    "   - Incorporar más datos históricos\n",
    "   - Explorar técnicas de series temporales más avanzadas\n",
    "   - Considerar variables macroeconómicas y noticias del sector\n",
    "   - Implementar técnicas de balanceo de clases para mejorar la predicción de clases minoritarias\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
